test


#m-provider.tf :프로바이더 생성


provider "aws" {
  #version = "~> 1.33"
  region  = "us-east-1"
}

provider "aws" {
  alias   = "califonia"   
  region  = "us-west-1"
}

#variable :변수생성
variable "amazon_linux_west" {
# Amazon Linux AMI 2017.03.1 (HVM), SSD Volume Type - ami-4af5022c
    default = "ami-04e59c05167ea7bd5"
}

variable "amazon_linux_east" {
# Amazon Linux AMI 2017.03.1 (HVM), SSD Volume Type - ami-4af5022c
    default = "ami-09d95fab7fff3776c"
}
variable "dev_keyname" {
    default = "Hholic"
}
variable "alb_account_id_east" {
    default = "127311923021"
}
variable "alb_account_id_west" {
    default = "027434742980"
}

#key.tf :키생성
resource "aws_key_pair" "Hholic-sshkey" {
  key_name   = "Hholic"
  public_key = "ssh-rsa ~~~~ ec2-user@ip-192-168-1-115"
}



#VPC.tf VPC생성
resource "aws_vpc" "east-vpc" {
cidr_block = "10.0.0.0/16"
enable_dns_hostnames = true
enable_dns_support = true
instance_tenancy = "default"
tags = {
Name = "east-vpc"
}
}

resource "aws_vpc" "west-vpc" {
provider = aws.califonia
cidr_block = "20.0.0.0/16"
enable_dns_hostnames = true
enable_dns_support = true
instance_tenancy = "default"
tags = {
Name = "west-vpc"
}
}

#Subnet.tf : 서브넷 생성
resource "aws_subnet" "east-1-public_1a" {
vpc_id = aws_vpc.east-vpc.id
availability_zone = "us-east-1a"
cidr_block = "10.0.1.0/24"
tags = {
Name = "east-1-public-1a"
}
}

resource "aws_subnet" "east-1-public_1c" {
vpc_id = aws_vpc.east-vpc.id
availability_zone = "us-east-1c"
cidr_block = "10.0.2.0/24"
tags = {
Name = "east-1-public-1c"
}
}
h
resource "aws_subnet" "west-1-public_1a" {
provider = aws.califonia
vpc_id = aws_vpc.west-vpc.id
availability_zone = "us-west-1a"
cidr_block = "20.0.1.0/24"
tags = {
Name = "west-1st-1-public-1a"
}
}

resource "aws_subnet" "west-1-public_1c" {
provider = aws.califonia
vpc_id = aws_vpc.west-vpc.id
availability_zone = "us-west-1c"
cidr_block = "20.0.2.0/24"
tags = {
Name = "west-1st-1-public-1c"
}
}


#IGW.tf : 인터넷게이트웨이 생성

resource "aws_internet_gateway" "esat-1-IGW" {
vpc_id = aws_vpc.east-vpc.id
tags = {
Name = "esat-1-IGW"
}
}

resource "aws_internet_gateway" "west-1-IGW" {
provider =aws.califonia
vpc_id = aws_vpc.west-vpc.id
tags = {
Name = "west-1-IGW"
}
}


#RouteTable.tf : 기본 라우팅 테이블 생성

resource "aws_route_table" "rt-east-1-public"{
    vpc_id= aws_vpc.east-vpc.id
        route {
            cidr_block= "0.0.0.0/0"
            gateway_id= aws_internet_gateway.esat-1-IGW.id
              }
    tags = {
    Name = "rt-east-1-public"
        }
}

resource "aws_route_table_association" "rt-east-1_public_1a"{
subnet_id= aws_subnet.east-1-public_1a.id
route_table_id=aws_route_table.rt-east-1-public.id
}

resource "aws_route_table_association" "rt-east-1_public_1c"{
subnet_id= aws_subnet.east-1-public_1c.id
route_table_id= aws_route_table.rt-east-1-public.id
}



resource "aws_route_table" "rt-west-1-public"{
    provider =aws.califonia
    vpc_id= aws_vpc.west-vpc.id
        route {
            cidr_block= "0.0.0.0/0"
            gateway_id= aws_internet_gateway.west-1-IGW.id
              }
    tags = {
    Name = "rt-west-1-public"
        }
}

resource "aws_route_table_association" "rt-west-1_public_1a"{
provider =aws.califonia
subnet_id= aws_subnet.west-1-public_1a.id
route_table_id=aws_route_table.rt-west-1-public.id
}

resource "aws_route_table_association" "rt-west-1_public_1c"{
provider =aws.califonia
subnet_id= aws_subnet.west-1-public_1c.id
route_table_id= aws_route_table.rt-west-1-public.id
}


#DFT-SG 기본 시큐리티 그룹 생성

resource "aws_default_security_group" "esat-vpc_SG_DFT" {
    vpc_id= aws_vpc.east-vpc.id
        ingress {
            protocol = -1
            self = true
            from_port = 0
            to_port = 0
            }
        egress {
            from_port = 0
            to_port = 0
            protocol = "-1"
            cidr_blocks = ["0.0.0.0/0"]
            }
    tags = {
        Name = "esat-vpc_SG_DFT"
            }
        }

resource "aws_default_security_group" "west-vpc_SG_DFT" {
    provider =aws.califonia
    vpc_id= aws_vpc.west-vpc.id
        ingress {
            protocol = -1
            self = true
            from_port = 0
            to_port = 0
            }
        egress {
            from_port = 0
            to_port = 0
            protocol = "-1"
            cidr_blocks = ["0.0.0.0/0"]
            }
    tags = {
        Name = "west-vpc_SG_DFT"
            }
        }


#alb-SG :어플리케이션 로드발란서용 시큐리티 그룹 생성
resource "aws_security_group" "east-alb-SG" {
    name = "esat-alb-SG"
    description = "open HTTP port for ALB"
    vpc_id = "${aws_vpc.east-vpc.id}"
    #vpc_id = "${aws_vpc.user05_vpc_A.id}"
        ingress {
            from_port = 80
            to_port = 80
            protocol = "tcp"
            cidr_blocks = ["0.0.0.0/0"]
                }
          ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
        egress {
            from_port = 0
            to_port = 0
            protocol = "-1"
            cidr_blocks = ["0.0.0.0/0"]
                }
    tags = {
        Name = "east-alb-SG"
            }
}

resource "aws_security_group" "west-alb-SG" {
    provider = aws.califonia
    name = "west-alb-SG"
    description = "open HTTP port for ALB"
    vpc_id = "${aws_vpc.west-vpc.id}"

        ingress {
            from_port = 80
            to_port = 80
            protocol = "tcp"
            cidr_blocks = ["0.0.0.0/0"]
                }
          ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
        egress {
            from_port = 0
            to_port = 0
            protocol = "-1"
            cidr_blocks = ["0.0.0.0/0"]
                }
    tags = {
        Name = "west-alb-SG"
            }
}





#vpc-pc :peer링커낵션 생성 및 라우팅 추가



data "aws_caller_identity" "west-peer" {
  provider = aws.califonia
}

# Requester's side of the connection.
resource "aws_vpc_peering_connection" "west-peer" {
  vpc_id        = aws_vpc.east-vpc.id
  peer_vpc_id   = aws_vpc.west-vpc.id
  peer_owner_id = data.aws_caller_identity.west-peer.account_id
  peer_region   = "us-west-1"
  auto_accept   = false

  tags = {
    Side = "Requester"
  }
}

# Accepter's side of the connection.
resource "aws_vpc_peering_connection_accepter" "west-peer" {
  provider                  = aws.califonia
  vpc_peering_connection_id = aws_vpc_peering_connection.west-peer.id
  auto_accept               = true

  tags = {
    Side = "Accepter"
  }
}



resource "aws_route" "peer-east-rt" {
  route_table_id            = aws_route_table.rt-east-1-public.id
  destination_cidr_block    = aws_vpc.west-vpc.cidr_block
  vpc_peering_connection_id = aws_vpc_peering_connection.west-peer.id
}

resource "aws_route" "peer-west-rt" {
  provider = aws.califonia
  route_table_id            = aws_route_table.rt-west-1-public.id
  destination_cidr_block    = aws_vpc.east-vpc.cidr_block
  vpc_peering_connection_id = aws_vpc_peering_connection.west-peer.id
}



#createS3 :alb 로그를 위한 S3 버킷 생성
resource "aws_s3_bucket" "hholic-alb-s3" {
    bucket = "hholic-alb-log.com"
    policy = <<EOF
{
        "Version": "2012-10-17",
        "Statement": [
        {
        "Effect": "Allow",
        "Principal": {
            "AWS": "arn:aws:iam::${var.alb_account_id_east}:root","AWS": "arn:aws:iam::${var.alb_account_id_west}:root"
                    },
        "Action": "s3:PutObject",
        "Resource": "arn:aws:s3:::hholic-alb-log.com/*"
        }
    ]
}
EOF
lifecycle_rule {
id = "log_lifecycle"
prefix = ""
enabled = true
transition {
days = 30
storage_class = "GLACIER"
}
expiration {
days = 90
}
}
lifecycle {
prevent_destroy = false
}
}






#alb-TG.tf 

resource "aws_alb_target_group" "hholic-east-frontend" {
name = "hholic-east-frontend-TG"
port = 80
protocol = "HTTP"
vpc_id = "${aws_vpc.east-vpc.id}"
health_check {
interval = 30
path = "/"
healthy_threshold = 3
unhealthy_threshold = 3
}
tags = { Name = "Frontend Target Group" }
}

#resource "aws_alb_target_group_attachment" "frontend" {
#target_group_arn = "${aws_alb_target_group.user05-frontend.arn}"
#target_id = "${aws_instance.user05_ec2_1a.id}"
#port = 80
#}
#resource "aws_alb_target_group_attachment" "frontend_1c" {
#target_group_arn = "${aws_alb_target_group.user05-frontend.arn}"
#target_id = "${aws_instance.user05_EC2_1c.id}"
#port = 80
#}




#alb-listener.tf

resource "aws_alb_listener" "hholic-east-http" {
load_balancer_arn = "${aws_alb.hholic-east-alb.arn}"
port = "80"
protocol = "HTTP"
default_action {
target_group_arn = "${aws_alb_target_group.hholic-east-frontend.arn}"
type = "forward"
}
}



#autoscale-alb.tf
resource "aws_alb" "hholic-east-alb" {
    name = "hholic-east-alb-autoscaling"
    internal = false
    security_groups = ["${aws_security_group.east-alb-SG.id}"]
    subnets = [
       "${aws_subnet.east-1-public_1a.id}",
       "${aws_subnet.east-1-public_1c.id}"
    ]
    access_logs {
        bucket = "${aws_s3_bucket.hholic-alb-s3.id}"
        prefix = "frontend-alb"
        enabled = true
    }
    tags = {
        Name = "hholic-east--alb-autoscaling"
    }
    lifecycle { create_before_destroy = true }
}



#alb-launch.tf

resource "aws_launch_configuration" "east-web" {
  name_prefix = "east-autoscaling-web"

  image_id = "${var.amazon_linux}"
  instance_type = "t2.nano"
  key_name = "Hholic"
  security_groups = [
    "${aws_security_group.east-alb-SG.id}",
    "${aws_default_security_group.esat-vpc_SG_DFT.id}",
  ]
  associate_public_ip_address = true
    
  user_data = <<USER_DATA
#!/bin/bash
yum update
yum -y install httpd
echo "<html>" > /var/www/html/index.html
echo "Hello" >> /var/www/html/index.html
echo "<img src=\"CloudFront URL\"> >> /var/www/html/index.html"
echo "</html>" >> /var/www/html/index.html
systemctl start httpd.service
systemctl enable httpd.service
  USER_DATA

  lifecycle {
    create_before_destroy = true
  }
}



#alb-autoscaling-GP.tf


resource "aws_autoscaling_group" "east-web" {
  name = "${aws_launch_configuration.east-web.name}-asg"

  min_size             = 1
  desired_capacity     = 2
  max_size             = 3

  health_check_type    = "ELB"
  #load_balancers= ["${aws_alb.alb.id}" ] #classic
  target_group_arns   = ["${aws_alb_target_group.hholic-east-frontend.arn}"]
  #alb = "${aws_alb.alb.id}"
  
  launch_configuration = "${aws_launch_configuration.east-web.name}"
  ####  availability_zones = ["ap-southeast-1a", "ap-southeast-1b"]  아ㅐㄹ vpc_zone_identifier 와 중복

  enabled_metrics = [
    "GroupMinSize",
    "GroupMaxSize",
    "GroupDesiredCapacity",
    "GroupInServiceInstances",
    "GroupTotalInstances"
  ]

  metrics_granularity="1Minute"

  vpc_zone_identifier  = [
       "${aws_subnet.east-1-public_1a.id}",
       "${aws_subnet.east-1-public_1c.id}"
  ]

  # Required to redeploy without an outage.
  lifecycle {
    create_before_destroy = true
  }

  tag {
    key                 = "Name"
    value               = "east-web-autoscaling"
    propagate_at_launch = true
  }
}

resource "aws_autoscaling_attachment" "east-asg-attachment" {
  autoscaling_group_name = aws_autoscaling_group.east-web.id
  alb_target_group_arn   = aws_alb_target_group.hholic-east-frontend.arn
}


#autoscaling-policy.tf
#UP
resource "aws_autoscaling_policy" "east-web_policy_up" {
  name = "east-web_policy_up"
  scaling_adjustment = 1
  adjustment_type = "ChangeInCapacity"
  cooldown = 10
  autoscaling_group_name = "${aws_autoscaling_group.web-05.name}"
}

resource "aws_cloudwatch_metric_alarm" "web_cpu_alarm_up" {
  alarm_name = "east-web_cpu_alarm_up"
  comparison_operator = "GreaterThanOrEqualToThreshold"
  evaluation_periods = "2"
  metric_name = "CPUUtilization"
  namespace = "AWS/EC2"
  period = "120"
  statistic = "Average"
  threshold = "20"

  #dimensions {
  #  AutoScalingGroupName = "${aws_autoscaling_group.web.name}"
  #}

  alarm_description = "This metric monitor EC2 instance CPU utilization"
  alarm_actions = ["${aws_autoscaling_policy.east-web_policy_up.arn}"]
}

#Down
resource "aws_autoscaling_policy" "east-web_policy_down" {
  name = "east-web_policy_down"
  scaling_adjustment = -1
  adjustment_type = "ChangeInCapacity"
  cooldown = 10
  autoscaling_group_name = "${aws_autoscaling_group.east-web.name}"
}

resource "aws_cloudwatch_metric_alarm" "web_cpu_alarm_down" {
  alarm_name = "east-web_cpu_alarm_down"
  comparison_operator = "LessThanOrEqualToThreshold"
  evaluation_periods = "2"
  metric_name = "CPUUtilization"
  namespace = "AWS/EC2"
  period = "120"
  statistic = "Average"
  threshold = "10"

  #dimensions {
  #  AutoScalingGroupName = "${aws_autoscaling_group.east-web.name}"
  #:}

  alarm_description = "This metric monitor EC2 instance CPU utilization"
  alarm_actions = ["${aws_autoscaling_policy.east-web_policy_down.arn}"]
}





   1  git
    2  git init
    3  git pull
    4  git clone https://github.com/minsookim78/AWS-Team-PJ.git
    5  ls
    6  wget https://releases.hashicorp.com/terraform/0.12.26/terraform_0.12.26_linux_amd64.zip
    7  unzip terraform_0.12.26_linux_amd64.zip 
    8  cd ~/.ssh/
    9  ls
   10  cat authorized_keys 
   11  ssh-keygen -t rsa
   12  ls
   13  cat id_rsa.pub 
   14  nano authorized_keys 
   15  cp id_rsa.pub Hholic.pem
   16  cat Hholic.pem 
   17  cd ~/environment/
   18  ./terraform plan
   
   27  ./terraform plan
   28  cd ~/.ssh/
   29  ls
   30  chmod 400 Hholic.pem
   31  ssh -i "Hholic.pem" ec2-user@ec2-52-90-21-51.compute-1.amazonaws.com
   32  cat Hholic.pem 
   33  ls
   34  history
   35  cat id_rsa
   36  ls
   37  rm Hholic.pem 
   38  ls
   39  cp id_rsa Hholic.pem
   40  chmod 400 Hholic.pem
   41  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   42  ls
   43  cat authorized_keys 
   44  cat known_hosts 
   45  nano known_hosts 
   46  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   47  ls
   48  rm Hholic.pem 
   49  cp id_rsa.pub Hholic.pem
   50  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   51  chmod 400 Hholic.pem
   52  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   53  ssh-keygen -f Hholic -m pem -p
   54  ssh-keygen -f  -m pem -p
   55  ssh-keygen -f id_rsa.pub -m pem -p
   56  openssl rsa -in id_rsa -pubout -out id_rsa.pub.pe
   57  openssl rsa -in id_rsa -pubout -out id_rsa.pub.pem
   58  ls
   59  cat id_rsa.pub.pem 
   60  cat id_rsa.pub
   61  cp id_rsa.pub Hholic.pub
   62  cp id_rsa.pub.pem Hholic.pem
   63  ls
   64  rm Hholic.pem 
   65  cp id_rsa.pub.pem Hholic.pem
   66  ls
   67  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   68  chmod 440 Hholic.pem 
   69  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   70  chmod 400 Hholic.pem 
   71  ssh -i "Hholic.pem" ec2-user@ec2-3-230-147-141.compute-1.amazonaws.com
   72  history
   73  ls
   74  rm Hholic.pem Hholic.pub id_rsa id_rsa.pub id_rsa.pub.pe id_rsa.pub.pem
   75  ls
   76  ssh-keygen 
   77  ls
   78  cat id_rsa.pub 
   79  nano authorized_keys 
   80  cp id_rsa Hholic.pem
   81  cp id_rsa.pub Hholic.pub
   82  cat Hholic.pub 
   83  chmod 400 Hholic.pem 
   84  ssh -i "Hholic.pem" ec2-user@ec2-3-90-2-99.compute-1.amazonaws.com
   85  ssh -i "Hholic.pem" ec2-user@ec2-54-157-97-89.compute-1.amazonaws.com
   86  git
   87  git init
   88  ls
   89  git add Hholic.pem 
   90  git add Hholic.pub 
   91  git commit -m "v1 0"
   92  git pull https://github.com/minsookim78/AWS-Team-PJ.git
   93  git log
   94  git push origin master
   95  git status
   96  git remote add origin master
   97  git push origin master
   98  git push master https://github.com/minsookim78/AWS-Team-PJ.git
   99  git remote add origin https://github.com/minsookim78/AWS-Team-PJ.git
  100  git push origin master
  101  git init
  102  git log
  103  git status
  104  git remote add origin https://github.com/minsookim78/AWS-Team-PJ.git
  105  git remote add https://github.com/minsookim78/AWS-Team-PJ.git
  106  git remote -v
  107  git clone https://github.com/minsookim78/AWS-Team-PJ.git
  108  git remote -v
  109  ls
  110  git push origin master
  111  git remote -v
  112  git remote add https://github.com/minsookim78/AWS-Team-PJ.git
  113  git remote add origin https://github.com/minsookim78/AWS-Team-PJ.git
  114  git remote delete origin master
  115  history



data "aws_s3_bucket" "selected" {
  bucket = "a-test-bucket"
}

resource "aws_cloudfront_distribution" "test" {
  origin {
    domain_name = "${data.aws_s3_bucket.selected.bucket_domain_name}"
    origin_id   = "s3-selected-bucket"
  }
}
